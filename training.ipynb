{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2048.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNWOF+idF+rb/GF1/aocE/N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jscscloris/2048-api/blob/master/2048.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC53a8uByPLX",
        "colab_type": "text"
      },
      "source": [
        "初始数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCzn7aWFyE17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/driver/Shared\\ drives/jscscloris@gmail.com/2048-api\n",
        "from game2048.game import Game\n",
        "from game2048.displays import Display, IPythonDisplay\n",
        "from game2048.agents import Agent, RandomAgent, ExpectiMaxAgent\n",
        "import numpy as np\n",
        "import json\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import torch\n",
        "\n",
        "map_table={2**i:i for i in range(1,16)}\n",
        "map_table[0]=0\n",
        "def grid_ohe(arr):\n",
        "  ret=np.zeros(shape=(4,4,16),dtype=float)\n",
        "  for r in range(4):\n",
        "    for c in range(4):\n",
        "      ret[r,c,map_table[arr[r,c]]]=1\n",
        "  return ret\n",
        "  \n",
        "X_train_64=[]\n",
        "Y_train_64=[]\n",
        "X_train_128=[]\n",
        "Y_train_128=[]\n",
        "X_train_256=[]\n",
        "Y_train_256=[]\n",
        "X_train_512=[]\n",
        "Y_train_512=[]\n",
        "X_train_1024=[]\n",
        "Y_train_1024=[]\n",
        "iters=1000\n",
        "\n",
        "for i in range(iters):\n",
        "  game = Game(4, score_to_win=2048, random=False)\n",
        "  agent = ExpectiMaxAgent(game)\n",
        "  while game.end==0:  \n",
        "    bd=np.array(game.board)\n",
        "    bd_ohe=grid_ohe(bd)\n",
        "    bd_ohe=np.swapaxes(bd_ohe,0,2)\n",
        "    score=game.score\n",
        "    direction = agent.step()\n",
        "    if score<=64:\n",
        "      X_train_64.append(bd_ohe)\n",
        "      Y_train_64.append([direction])\n",
        "    elif score==128:\n",
        "      X_train_128.append(bd_ohe)\n",
        "      Y_train_128.append([direction])\n",
        "    elif score==256:\n",
        "      X_train_256.append(bd_ohe)\n",
        "      Y_train_256.append([direction])  \n",
        "    elif score==512:\n",
        "      X_train_512.append(bd_ohe)\n",
        "      Y_train_512.append([direction]) \n",
        "    else:\n",
        "      X_train_1024.append(bd_ohe)\n",
        "      Y_train_1024.append([direction])\n",
        "    game.move(direction) \n",
        "  print('iter:',i)\n",
        "\n",
        "print('length of dataset64:',len(X_train_64))\n",
        "print('length of dataset128:',len(X_train_128))\n",
        "print('length of dataset256:',len(X_train_256))\n",
        "print('length of dataset512:',len(X_train_512))\n",
        "print('length of dataset1024:',len(X_train_1024))\n",
        "X=np.array(X_train_64) \n",
        "Y=np.array(Y_train_64) \n",
        "np.save('X_train_64.npy', X)\n",
        "np.save('Y_train_64.npy', Y)\n",
        "X=np.array(X_train_128) \n",
        "Y=np.array(Y_train_128) \n",
        "np.save('X_train_128.npy', X)\n",
        "np.save('Y_train_128.npy', Y)\n",
        "X=np.array(X_train_256) \n",
        "Y=np.array(Y_train_256) \n",
        "np.save('X_train_256.npy', X)\n",
        "np.save('Y_train_256.npy', Y)\n",
        "X=np.array(X_train_512) \n",
        "Y=np.array(Y_train_512) \n",
        "np.save('X_train_512.npy', X)\n",
        "np.save('Y_train_512.npy', Y)\n",
        "X=np.array(X_train_1024) \n",
        "Y=np.array(Y_train_1024) \n",
        "np.save('X_train_1024.npy', X)\n",
        "np.save('Y_train_1024.npy', Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnHGcAEcxUyy",
        "colab_type": "text"
      },
      "source": [
        "训练部分"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtLzss-BxCcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(16, 64, kernel_size=(4, 1), padding=(2, 0))\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(1, 4), padding=(0, 2))\n",
        "        self.conv3 = nn.Conv2d(128, 128, kernel_size=(2, 2))\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=(3, 3), padding=(1, 1))\n",
        "        self.conv5 = nn.Conv2d(128, 128, kernel_size=(4, 4), padding=(2, 2))\n",
        "        self.conv6 = nn.Conv2d(128,128,kernel_size=(2,2))\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 512)\n",
        "        self.fc3 = nn.Linear(512, 4)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(128 * 4 * 4)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
        "        self.batch_norm3 = nn.BatchNorm1d(512)\n",
        "\n",
        "        self.initialize()\n",
        "\n",
        "    def forward(self,x):        \n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.batch_norm2(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.batch_norm3(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def initialize(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_uniform_(m.weight, mode='fan_in')\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight, mode='fan_in')\n",
        "\n",
        "batch_size = 128\n",
        "NUM_EPOCHS = 200\n",
        "\n",
        "X_train=np.load('X_train_64.npy')\n",
        "Y_train=np.load('Y_train_64.npy')\n",
        "train_db = TensorDataset(torch.Tensor(X_train).float(), torch.squeeze(torch.Tensor(Y_train)))\n",
        "train_loader_64 = DataLoader(train_db, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "X_train=np.load('X_train_128.npy')\n",
        "Y_train=np.load('Y_train_128.npy')\n",
        "train_db = TensorDataset(torch.Tensor(X_train).float(), torch.squeeze(torch.Tensor(Y_train)))\n",
        "train_loader_128 = DataLoader(train_db, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "X_train=np.load('X_train_256.npy')\n",
        "Y_train=np.load('Y_train_256.npy')\n",
        "train_db = TensorDataset(torch.Tensor(X_train).float(), torch.squeeze(torch.Tensor(Y_train)))\n",
        "train_loader_256 = DataLoader(train_db, batch_size=batch_size, shuffle=True,drop_last=True)\n",
        "\n",
        "X_train=np.load('X_train_512.npy')\n",
        "Y_train=np.load('Y_train_512.npy')\n",
        "train_db = TensorDataset(torch.Tensor(X_train).float(), torch.squeeze(torch.Tensor(Y_train)))\n",
        "train_loader_512 = DataLoader(train_db, batch_size=batch_size, shuffle=True,drop_last=True)\n",
        "\n",
        "X_train=np.load('X_train_1024.npy')\n",
        "Y_train=np.load('Y_train_1024.npy')\n",
        "train_db = TensorDataset(torch.Tensor(X_train).float(), torch.squeeze(torch.Tensor(Y_train)))\n",
        "train_loader_1024 = DataLoader(train_db, batch_size=batch_size, shuffle=True,drop_last=True)\n",
        "model = Net()\n",
        "model = model.cuda()\n",
        "loss_func=nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "model.train()\n",
        "\n",
        "model.load_state_dict(torch.load('64_epoch_200.pkl'))\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for step, (X_train, Y_train) in enumerate(train_loader_64):\n",
        "    X_train=Variable(X_train).cuda()\n",
        "    Y_train=Variable(Y_train).cuda()\n",
        "    optimizer.zero_grad()\n",
        "    output=model(X_train)\n",
        "    loss = loss_func(output,Y_train.long())    \n",
        "    loss.backward()\n",
        "    optimizer.step()  \n",
        "  if (epoch+1)%100==0:\n",
        "    print('save64',(epoch+1),loss)\n",
        "    torch.save(model.state_dict(), '64_epoch_{}.pkl'.format((epoch+1)))\n",
        "\n",
        "model.load_state_dict(torch.load('128_epoch_200.pkl'))\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for step, (X_train, Y_train) in enumerate(train_loader_128):\n",
        "    X_train=Variable(X_train).cuda()\n",
        "    Y_train=Variable(Y_train).cuda()\n",
        "    optimizer.zero_grad()\n",
        "    output=model(X_train)\n",
        "    loss = loss_func(output,Y_train.long())    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  if (epoch+1)%100==0:\n",
        "    print('save128',(epoch+1),loss)\n",
        "    torch.save(model.state_dict(), '128_epoch_{}.pkl'.format((epoch+1)))\n",
        "\n",
        "model.load_state_dict(torch.load('256_epoch_200.pkl'))\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for step, (X_train, Y_train) in enumerate(train_loader_256):\n",
        "    X_train=Variable(X_train).cuda()\n",
        "    Y_train=Variable(Y_train).cuda()\n",
        "    optimizer.zero_grad()\n",
        "    output=model(X_train)\n",
        "    loss = loss_func(output,Y_train.long())    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  if (epoch+1)%100==0:\n",
        "    print('save256',(epoch+1),loss)\n",
        "    torch.save(model.state_dict(), '256_epoch_{}.pkl'.format((epoch+1)))\n",
        "\n",
        "model.load_state_dict(torch.load('512_epoch_400.pkl'))\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for step, (X_train, Y_train) in enumerate(train_loader_512):\n",
        "    X_train=Variable(X_train).cuda()\n",
        "    Y_train=Variable(Y_train).cuda()\n",
        "    optimizer.zero_grad()\n",
        "    output=model(X_train)\n",
        "    loss = loss_func(output,Y_train.long())    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  if (epoch+1)%100==0:\n",
        "    print('save512',(epoch+1),loss)\n",
        "    torch.save(model.state_dict(), '512_epoch_{}.pkl'.format((epoch+1)))\n",
        "\n",
        "model.load_state_dict(torch.load('1024_epoch_200.pkl'))\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for step, (X_train, Y_train) in enumerate(train_loader_1024):\n",
        "    X_train=Variable(X_train).cuda()\n",
        "    Y_train=Variable(Y_train).cuda()\n",
        "    optimizer.zero_grad()\n",
        "    output=model(X_train)\n",
        "    loss = loss_func(output,Y_train.long())    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  if (epoch+1)%100==0:\n",
        "    print('save1024',(epoch+1),loss)\n",
        "    torch.save(model.state_dict(), '1024_epoch_{}.pkl'.format((epoch+1)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osM0X1zCxpAE",
        "colab_type": "text"
      },
      "source": [
        "数据增广部分"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tktgWQSxxreo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from game2048.game import Game\n",
        "from game2048.displays import Display, IPythonDisplay\n",
        "from game2048.agents import Agent, RandomAgent, ExpectiMaxAgent,MyOwnAgent\n",
        "import numpy as np\n",
        "import json\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import torch\n",
        "\n",
        "map_table={2**i:i for i in range(1,16)}\n",
        "map_table[0]=0\n",
        "def grid_ohe(arr):\n",
        "  ret=np.zeros(shape=(4,4,16),dtype=float)\n",
        "  for r in range(4):\n",
        "    for c in range(4):\n",
        "      ret[r,c,map_table[arr[r,c]]]=1\n",
        "  return ret\n",
        "  \n",
        "X_train_64=[]\n",
        "Y_train_64=[]\n",
        "X_train_128=[]\n",
        "Y_train_128=[]\n",
        "X_train_256=[]\n",
        "Y_train_256=[]\n",
        "X_train_512=[]\n",
        "Y_train_512=[]\n",
        "X_train_1024=[]\n",
        "Y_train_1024=[]\n",
        "iters=1000\n",
        "\n",
        "for i in range(iters):\n",
        "  game = Game(4, score_to_win=2048, random=False)\n",
        "  agent = MyOwnAgent(game)\n",
        "  expect = ExpectiMaxAgent(game)\n",
        "  while game.end==0:  \n",
        "    bd=np.array(game.board)\n",
        "    bd_ohe=grid_ohe(bd)\n",
        "    bd_ohe=np.swapaxes(bd_ohe,0,2)\n",
        "    score=game.score\n",
        "    direction = expect.step()\n",
        "    mo=agent.step()\n",
        "    if score<=64:\n",
        "      X_train_64.append(bd_ohe)\n",
        "      Y_train_64.append([direction])\n",
        "    elif score==128:\n",
        "      X_train_128.append(bd_ohe)\n",
        "      Y_train_128.append([direction])\n",
        "    elif score==256:\n",
        "      X_train_256.append(bd_ohe)\n",
        "      Y_train_256.append([direction])  \n",
        "    elif score==512:\n",
        "      X_train_512.append(bd_ohe)\n",
        "      Y_train_512.append([direction]) \n",
        "    else:\n",
        "      X_train_1024.append(bd_ohe)\n",
        "      Y_train_1024.append([direction])\n",
        "    game.move(mo) \n",
        "  \n",
        "\n",
        "print('length of dataset64:',len(X_train_64))\n",
        "print('length of dataset128:',len(X_train_128))\n",
        "print('length of dataset256:',len(X_train_256))\n",
        "print('length of dataset512:',len(X_train_512))\n",
        "print('length of dataset1024:',len(X_train_1024))\n",
        "\n",
        "X=np.array(X_train_64) \n",
        "Y=np.array(Y_train_64) \n",
        "raw_X=np.load('X_train_64.npy')\n",
        "raw_Y=np.load('Y_train_64.npy')\n",
        "new_X=np.concatenate((raw_X, X), axis=0)\n",
        "new_Y=np.concatenate((raw_Y, Y), axis=0)\n",
        "np.save('X_train_64.npy', new_X)\n",
        "np.save('Y_train_64.npy', new_Y)\n",
        "\n",
        "X=np.array(X_train_128) \n",
        "Y=np.array(Y_train_128) \n",
        "raw_X=np.load('X_train_128.npy')\n",
        "raw_Y=np.load('Y_train_128.npy')\n",
        "new_X=np.concatenate((raw_X, X), axis=0)\n",
        "new_Y=np.concatenate((raw_Y, Y), axis=0)\n",
        "np.save('X_train_128.npy', new_X)\n",
        "np.save('Y_train_128.npy', new_Y)\n",
        "\n",
        "X=np.array(X_train_256) \n",
        "Y=np.array(Y_train_256) \n",
        "raw_X=np.load('X_train_256.npy')\n",
        "raw_Y=np.load('Y_train_256.npy')\n",
        "new_X=np.concatenate((raw_X, X), axis=0)\n",
        "new_Y=np.concatenate((raw_Y, Y), axis=0)\n",
        "np.save('X_train_256.npy', new_X)\n",
        "np.save('Y_train_256.npy', new_Y)\n",
        "\n",
        "X=np.array(X_train_512) \n",
        "Y=np.array(Y_train_512) \n",
        "raw_X=np.load('X_train_512.npy')\n",
        "raw_Y=np.load('Y_train_512.npy')\n",
        "new_X=np.concatenate((raw_X, X), axis=0)\n",
        "new_Y=np.concatenate((raw_Y, Y), axis=0)\n",
        "np.save('X_train_512.npy', new_X)\n",
        "np.save('Y_train_512.npy', new_Y)\n",
        "\n",
        "X=np.array(X_train_1024) \n",
        "Y=np.array(Y_train_1024) \n",
        "raw_X=np.load('X_train_1024.npy')\n",
        "raw_Y=np.load('Y_train_1024.npy')\n",
        "new_X=np.concatenate((raw_X, X), axis=0)\n",
        "new_Y=np.concatenate((raw_Y, Y), axis=0)\n",
        "np.save('X_train_1024.npy', new_X)\n",
        "np.save('Y_train_1024.npy', new_Y)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
